{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We follow the instructions from https://spacy.io/docs/usage/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting spacy\n",
      "Requirement already up-to-date: six in /usr/local/lib/python3.5/dist-packages (from spacy)\n",
      "Requirement already up-to-date: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.5/dist-packages (from spacy)\n",
      "Requirement already up-to-date: msgpack-numpy in /usr/local/lib/python3.5/dist-packages (from spacy)\n",
      "Requirement already up-to-date: dill<0.3,>=0.2 in /usr/local/lib/python3.5/dist-packages (from spacy)\n",
      "Requirement already up-to-date: cymem<1.32,>=1.30 in /usr/local/lib/python3.5/dist-packages (from spacy)\n",
      "Requirement already up-to-date: preshed<2.0.0,>=1.0.0 in /usr/local/lib/python3.5/dist-packages (from spacy)\n",
      "Requirement already up-to-date: thinc<6.11.0,>=6.10.1 in /usr/local/lib/python3.5/dist-packages (from spacy)\n",
      "Requirement already up-to-date: numpy>=1.7 in /usr/local/lib/python3.5/dist-packages (from spacy)\n",
      "Requirement already up-to-date: plac<1.0.0,>=0.9.6 in /usr/local/lib/python3.5/dist-packages (from spacy)\n",
      "Requirement already up-to-date: msgpack-python in /usr/local/lib/python3.5/dist-packages (from spacy)\n",
      "Requirement already up-to-date: pathlib in /usr/local/lib/python3.5/dist-packages (from spacy)\n",
      "Requirement already up-to-date: ujson>=1.35 in /usr/local/lib/python3.5/dist-packages (from spacy)\n",
      "Requirement already up-to-date: murmurhash<0.29,>=0.28 in /usr/local/lib/python3.5/dist-packages (from spacy)\n",
      "Requirement already up-to-date: regex==2017.4.5 in /usr/local/lib/python3.5/dist-packages (from spacy)\n",
      "Requirement already up-to-date: ftfy<5.0.0,>=4.4.2 in /usr/local/lib/python3.5/dist-packages (from spacy)\n",
      "Requirement already up-to-date: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.5/dist-packages (from requests<3.0.0,>=2.13.0->spacy)\n",
      "Requirement already up-to-date: idna<2.7,>=2.5 in /usr/local/lib/python3.5/dist-packages (from requests<3.0.0,>=2.13.0->spacy)\n",
      "Requirement already up-to-date: urllib3<1.23,>=1.21.1 in /usr/local/lib/python3.5/dist-packages (from requests<3.0.0,>=2.13.0->spacy)\n",
      "Requirement already up-to-date: certifi>=2017.4.17 in /usr/local/lib/python3.5/dist-packages (from requests<3.0.0,>=2.13.0->spacy)\n",
      "Requirement already up-to-date: tqdm<5.0.0,>=4.10.0 in /usr/local/lib/python3.5/dist-packages (from thinc<6.11.0,>=6.10.1->spacy)\n",
      "Requirement already up-to-date: termcolor in /usr/local/lib/python3.5/dist-packages (from thinc<6.11.0,>=6.10.1->spacy)\n",
      "Requirement already up-to-date: cytoolz<0.9,>=0.8 in /usr/local/lib/python3.5/dist-packages (from thinc<6.11.0,>=6.10.1->spacy)\n",
      "Requirement already up-to-date: wrapt in /usr/local/lib/python3.5/dist-packages (from thinc<6.11.0,>=6.10.1->spacy)\n",
      "Requirement already up-to-date: wcwidth in /usr/local/lib/python3.5/dist-packages (from ftfy<5.0.0,>=4.4.2->spacy)\n",
      "Requirement already up-to-date: html5lib in /usr/local/lib/python3.5/dist-packages (from ftfy<5.0.0,>=4.4.2->spacy)\n",
      "Requirement already up-to-date: toolz>=0.8.0 in /usr/local/lib/python3.5/dist-packages (from cytoolz<0.9,>=0.8->thinc<6.11.0,>=6.10.1->spacy)\n",
      "Collecting setuptools>=18.5 (from html5lib->ftfy<5.0.0,>=4.4.2->spacy)\n",
      "  Downloading setuptools-37.0.0-py2.py3-none-any.whl (481kB)\n",
      "\u001b[K    100% |████████████████████████████████| 491kB 3.1MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already up-to-date: webencodings in /usr/local/lib/python3.5/dist-packages (from html5lib->ftfy<5.0.0,>=4.4.2->spacy)\n",
      "Installing collected packages: spacy, setuptools\n",
      "  Found existing installation: setuptools 36.7.2\n",
      "    Uninstalling setuptools-36.7.2:\n",
      "      Successfully uninstalled setuptools-36.7.2\n",
      "Successfully installed setuptools-37.0.0 spacy-2.0.3\n"
     ]
    }
   ],
   "source": [
    "!sudo -H python3 -m pip install -U spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install Models for various languages\n",
    "\n",
    "See https://spacy.io/usage/models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting https://github.com/explosion/spacy-models/releases/download/en_core_web_lg-2.0.0/en_core_web_lg-2.0.0.tar.gz\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_lg-2.0.0/en_core_web_lg-2.0.0.tar.gz (852.3MB)\n",
      "\u001b[K    100% |████████████████████████████████| 852.3MB 49.8MB/s ta 0:00:013   40% |█████████████                   | 345.7MB 84.9MB/s eta 0:00:06    49% |███████████████▉                | 421.2MB 86.0MB/s eta 0:00:06 |████████████████████▊           | 550.6MB 87.1MB/s eta 0:00:04MB 69.9MB/s eta 0:00:049.9MB/s eta 0:00:03█████▎         | 593.5MB 89.2MB/s eta 0:00:03█████▋         | 602.8MB 73.6MB/s eta 0:00:04��██████         | 613.0MB 102.6MB/s eta 0:00:03��████████████████▍        | 621.6MB 82.0MB/s eta 0:00:03��███████████████▌        | 626.1MB 80.0MB/s eta 0:00:03�██████████████████▏      | 671.7MB 78.9MB/s eta 0:00:0300:0303 0:00:03   | 693.5MB 75.4MB/s eta 0:00:03 697.0MB 78.3MB/s eta 0:00:02�█████▍     | 704.2MB 89.2MB/s eta 0:00:02█████▊     | 712.5MB 87.2MB/s eta 0:00:02█████████     | 719.6MB 82.5MB/s eta 0:00:026MB/s eta 0:00:02�████████████████▎    | 727.4MB 84.9MB/s eta 0:00:02�████████████████▌    | 731.2MB 81.5MB/s eta 0:00:02��██████████████████▋    | 735.2MB 89.6MB/s eta 0:00:02��███████████████████▉    | 742.2MB 75.5MB/s eta 0:00:02�█████████████████    | 745.1MB 75.8MB/s eta 0:00:02█████████▎   | 751.7MB 81.8MB/s eta 0:00:02   88% |████████████████████████████▍   | 756.2MB 84.1MB/s eta 0:00:02[K    89% |████████████████████████████▌   | 760.2MB 81.7MB/s eta 0:00:023.4MB 87.4MB/s eta 0:00:02 0:00:02�██████████████████   | 770.7MB 79.6MB/s eta 0:00:02█████████████████████████   | 773.8MB 89.4MB/s eta 0:00:01�██████████████████▎  | 780.4MB 87.5MB/s eta 0:00:01��█▌  | 786.2MB 80.4MB/s eta 0:00:0185.7MB/s eta 0:00:01.7MB 73.6MB/s eta 0:00:01�████  | 799.7MB 81.7MB/s eta 0:00:01�█████▏ | 803.4MB 56.0MB/s eta 0:00:01�█████████████████████████▍ | 810.2MB 84.4MB/s eta 0:00:01��████████▌ | 813.8MB 60.4MB/s eta 0:00:01��████████████████████████████▊ | 817.7MB 80.6MB/s eta 0:00:01�█████████████████████▉ | 821.7MB 78.3MB/s eta 0:00:01MB 85.7MB/s eta 0:00:01��██████████████▏| 828.7MB 85.9MB/s eta 0:00:01�█████████████████▎| 832.1MB 86.3MB/s eta 0:00:01████████████████████▍| 835.2MB 79.1MB/s eta 0:00:01|███████████████████████████████▌| 838.7MB 87.4MB/s eta 0:00:01:00:01�███████████████████▊| 844.6MB 87.4MB/s eta 0:00:01█████████▉| 847.5MB 89.6MB/s eta 0:00:01\n",
      "\u001b[?25h  Requirement already satisfied (use --upgrade to upgrade): en-core-web-lg==2.0.0 from https://github.com/explosion/spacy-models/releases/download/en_core_web_lg-2.0.0/en_core_web_lg-2.0.0.tar.gz in /usr/local/lib/python3.5/dist-packages\n",
      "Requirement already satisfied: spacy>=2.0.0a18 in /usr/local/lib/python3.5/dist-packages (from en-core-web-lg==2.0.0)\n",
      "Requirement already satisfied: ujson>=1.35 in /usr/local/lib/python3.5/dist-packages (from spacy>=2.0.0a18->en-core-web-lg==2.0.0)\n",
      "Requirement already satisfied: cymem<1.32,>=1.30 in /usr/local/lib/python3.5/dist-packages (from spacy>=2.0.0a18->en-core-web-lg==2.0.0)\n",
      "Requirement already satisfied: msgpack-numpy in /usr/local/lib/python3.5/dist-packages (from spacy>=2.0.0a18->en-core-web-lg==2.0.0)\n",
      "Requirement already satisfied: preshed<2.0.0,>=1.0.0 in /usr/local/lib/python3.5/dist-packages (from spacy>=2.0.0a18->en-core-web-lg==2.0.0)\n",
      "Requirement already satisfied: numpy>=1.7 in /usr/local/lib/python3.5/dist-packages (from spacy>=2.0.0a18->en-core-web-lg==2.0.0)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.5/dist-packages (from spacy>=2.0.0a18->en-core-web-lg==2.0.0)\n",
      "Requirement already satisfied: ftfy<5.0.0,>=4.4.2 in /usr/local/lib/python3.5/dist-packages (from spacy>=2.0.0a18->en-core-web-lg==2.0.0)\n",
      "Requirement already satisfied: msgpack-python in /usr/local/lib/python3.5/dist-packages (from spacy>=2.0.0a18->en-core-web-lg==2.0.0)\n",
      "Requirement already satisfied: plac<1.0.0,>=0.9.6 in /usr/local/lib/python3.5/dist-packages (from spacy>=2.0.0a18->en-core-web-lg==2.0.0)\n",
      "Requirement already satisfied: dill<0.3,>=0.2 in /usr/local/lib/python3.5/dist-packages (from spacy>=2.0.0a18->en-core-web-lg==2.0.0)\n",
      "Requirement already satisfied: murmurhash<0.29,>=0.28 in /usr/local/lib/python3.5/dist-packages (from spacy>=2.0.0a18->en-core-web-lg==2.0.0)\n",
      "Requirement already satisfied: thinc<6.11.0,>=6.10.1 in /usr/local/lib/python3.5/dist-packages (from spacy>=2.0.0a18->en-core-web-lg==2.0.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.5/dist-packages (from spacy>=2.0.0a18->en-core-web-lg==2.0.0)\n",
      "Requirement already satisfied: regex==2017.4.5 in /usr/local/lib/python3.5/dist-packages (from spacy>=2.0.0a18->en-core-web-lg==2.0.0)\n",
      "Requirement already satisfied: pathlib in /usr/local/lib/python3.5/dist-packages (from spacy>=2.0.0a18->en-core-web-lg==2.0.0)\n",
      "Requirement already satisfied: html5lib in /usr/local/lib/python3.5/dist-packages (from ftfy<5.0.0,>=4.4.2->spacy>=2.0.0a18->en-core-web-lg==2.0.0)\n",
      "Requirement already satisfied: wcwidth in /usr/local/lib/python3.5/dist-packages (from ftfy<5.0.0,>=4.4.2->spacy>=2.0.0a18->en-core-web-lg==2.0.0)\n",
      "Requirement already satisfied: wrapt in /usr/local/lib/python3.5/dist-packages (from thinc<6.11.0,>=6.10.1->spacy>=2.0.0a18->en-core-web-lg==2.0.0)\n",
      "Requirement already satisfied: termcolor in /usr/local/lib/python3.5/dist-packages (from thinc<6.11.0,>=6.10.1->spacy>=2.0.0a18->en-core-web-lg==2.0.0)\n",
      "Requirement already satisfied: cytoolz<0.9,>=0.8 in /usr/local/lib/python3.5/dist-packages (from thinc<6.11.0,>=6.10.1->spacy>=2.0.0a18->en-core-web-lg==2.0.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.10.0 in /usr/local/lib/python3.5/dist-packages (from thinc<6.11.0,>=6.10.1->spacy>=2.0.0a18->en-core-web-lg==2.0.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.5/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.0.0a18->en-core-web-lg==2.0.0)\n",
      "Requirement already satisfied: urllib3<1.23,>=1.21.1 in /usr/local/lib/python3.5/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.0.0a18->en-core-web-lg==2.0.0)\n",
      "Requirement already satisfied: idna<2.7,>=2.5 in /usr/local/lib/python3.5/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.0.0a18->en-core-web-lg==2.0.0)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.5/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.0.0a18->en-core-web-lg==2.0.0)\n",
      "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.5/dist-packages (from html5lib->ftfy<5.0.0,>=4.4.2->spacy>=2.0.0a18->en-core-web-lg==2.0.0)\n",
      "Requirement already satisfied: webencodings in /usr/local/lib/python3.5/dist-packages (from html5lib->ftfy<5.0.0,>=4.4.2->spacy>=2.0.0a18->en-core-web-lg==2.0.0)\n",
      "Requirement already satisfied: toolz>=0.8.0 in /usr/local/lib/python3.5/dist-packages (from cytoolz<0.9,>=0.8->thinc<6.11.0,>=6.10.1->spacy>=2.0.0a18->en-core-web-lg==2.0.0)\n",
      "\n",
      "\u001b[93m    Linking successful\u001b[0m\n",
      "    /usr/local/lib/python3.5/dist-packages/en_core_web_lg -->\n",
      "    /usr/local/lib/python3.5/dist-packages/spacy/data/en_core_web_lg\n",
      "\n",
      "    You can now load the model via spacy.load('en_core_web_lg')\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Support for english\n",
    "!sudo python3 -m spacy download en_core_web_lg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Starting with Spacy\n",
    "\n",
    "We first import the library and create an `nlp` variable, instantiated for English (`'en'`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'spacy' has no attribute 'load'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-a9b0912ee35f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Load the space library, instantiated for English\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#note: the first time you run spaCy in a file it takes a little while to load up its modules\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mnlp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspacy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'en_core_web_lg'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: module 'spacy' has no attribute 'load'"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "# Load the space library, instantiated for English\n",
    "#note: the first time you run spaCy in a file it takes a little while to load up its modules\n",
    "nlp = spacy.load('en_core_web_lg') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From https://nicschrading.com/project/Intro-to-NLP-with-spaCy/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"There is an art, it says, or rather, a knack to flying. \n",
    "The knack lies in learning how to throw yourself at the ground and miss.\n",
    "In the beginning the Universe was created. This has made a lot of people\n",
    "very angry and been widely regarded as a bad move.\n",
    "This Prof. Panos, Ph.D. costs $12,345.67\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all you have to do to parse text is this:\n",
    "doc = nlp(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = [token for token in doc]\n",
    "tokens[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's look at the tokens\n",
    "# All you have to do is iterate through the doc\n",
    "# Each token is an object with lots of different properties\n",
    "# A property with an underscore at the end returns the string representation\n",
    "# while a property without the underscore returns an index (int) into spaCy's vocabulary\n",
    "# The probability estimate is based on counts from a 3 billion word corpus\n",
    "for i, token in enumerate(doc):\n",
    "    print(\"original:\", token.orth, token.orth_)\n",
    "    print(\"lowercased:\", token.lower, token.lower_)\n",
    "    print(\"lemma:\", token.lemma, token.lemma_)\n",
    "    print(\"shape:\", token.shape, token.shape_)\n",
    "    print(\"prefix:\", token.prefix, token.prefix_)\n",
    "    print(\"suffix:\", token.suffix, token.suffix_)\n",
    "    print(\"part of speech:\", token.pos_)\n",
    "    print(\"log probability:\", token.prob)\n",
    "    print(\"Brown cluster id:\", token.cluster)\n",
    "    print(\"----------------------------------------\")\n",
    "    if i > 1:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get some data\n",
    "\n",
    "First let's get a few text files, so that we can run our examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir data\n",
    "!curl -L 'https://raw.githubusercontent.com/cytora/pycon-nlp-in-10-lines/master/data/article.txt' -o data/article.txt\n",
    "!curl -L 'https://raw.githubusercontent.com/cytora/pycon-nlp-in-10-lines/master/data/pride_and_prejudice.txt' -o data/pride_and_prejudice.txt\n",
    "!curl -L 'https://raw.githubusercontent.com/cytora/pycon-nlp-in-10-lines/master/data/rand-terrorism-dataset.txt'  -o data/rand-terrorism-dataset.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will read the text file and then we will use the `nlp` object from spacy to analyze the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"data/article.txt\"\n",
    "text = open(filename, 'r').read()\n",
    "doc = nlp(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Print tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print tokens, one token per line\n",
    "# The enumerate function is just used to add a counter\n",
    "for token in doc:\n",
    "    print(token)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Print Sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the first 5 sentences (one sentence per line)\n",
    "# The enumerate function is just used to add a counter\n",
    "for i, sent in enumerate(doc.sents):\n",
    "    print(i, \"==>\", sent)\n",
    "    if i>5:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Named Entities "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entities = set([ent.lemma_ for ent in doc.ents])\n",
    "entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entities_with_type = set([ent.lemma_+\" # \"+ent.label_ for ent in doc.ents ])\n",
    "entities_with_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "organizations = set([ent.lemma_+\" # \"+ent.label_ for ent in doc.ents if ent.label_=='ORG' ])\n",
    "organizations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Noun chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks = [chunk.lemma_ for chunk in doc.noun_chunks if chunk.lemma_ not in entities]\n",
    "chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "keywords = Counter()\n",
    "for chunk in chunks:\n",
    "    # print(chunk, nlp.vocab[chunk].prob )\n",
    "    if nlp.vocab[chunk].prob < -8: # probablity value -8 is arbitrarily selected threshold\n",
    "        keywords[chunk] += 1\n",
    "\n",
    "keywords.most_common(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vector Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ent1 in doc.ents:\n",
    "    for ent2 in doc.ents:\n",
    "        similarity = ent1.similarity(ent2)\n",
    "        if similarity > 0.5:\n",
    "            print('{} - {} - {}' .format(ent1, ent2, similarity))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vector Embeddings Calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import dot\n",
    "from numpy.linalg import norm\n",
    "\n",
    "# cosine similarity\n",
    "cosine = lambda v1, v2: dot(v1, v2) / (norm(v1) * norm(v2))\n",
    "\n",
    "# Let's see if it can figure out this analogy\n",
    "# B is to A as C is to ???\n",
    "a = nlp.vocab['London']\n",
    "b = nlp.vocab['UK']\n",
    "c = nlp.vocab['France']\n",
    "\n",
    "# a = nlp.vocab['Knicks']\n",
    "# b = nlp.vocab['New York']\n",
    "# c = nlp.vocab['Boston']\n",
    "\n",
    "result = a.vector - b.vector + c.vector\n",
    "\n",
    "# gather all known words, take only the lowercased versions\n",
    "allWords = list({w for w in nlp.vocab if w.has_vector and w.is_title and w.lower_ not in set({a.lower_,b.lower_,c.lower_})})\n",
    "# sort by similarity to the result\n",
    "allWords.sort(key=lambda w: cosine(w.vector, result))\n",
    "allWords.reverse()\n",
    "print(\"\\n----------------------------\\nTop 3 closest results:\")\n",
    "for word in allWords[:3]:   \n",
    "    print(word.orth_)\n",
    "    \n",
    "# it got it! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
